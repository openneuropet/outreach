{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMQm1VCgU2Ol"
   },
   "source": [
    "# Brain Imaging Data Structure (BIDS) data conversion tutorial \n",
    "\n",
    "In the following Jupyter notebook, we will introduce you to BIDS basics. You will download some phantom data in neuroimaging formats as they come of a scanner and then work on converting it to BIDS format.\n",
    "Afterwards we will also spend time on how we can utilize data in BIDS format for easy processing of neuroimaging data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NdRZg4Q4wUs"
   },
   "source": [
    "## Collect the Repository and Install all Dependencies\n",
    "This may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XpjaKOjI3VsN",
    "outputId": "41cbac46-7d21-414c-88d2-887903af0610"
   },
   "outputs": [],
   "source": [
    "!if [ -d \"outreach\" ]; then echo \"Repo already cloned.\" && cd outreach && git pull && cd ..; else echo \"Collecting Outreach Repository\" && git clone https://github.com/openneuropet/outreach.git; fi\n",
    "from os.path import basename\n",
    "from os import getcwd\n",
    "if basename(getcwd()) == 'PETBIDS-Onboarding2025':\n",
    "    pass\n",
    "else:\n",
    "    %cd outreach/PETBIDS-Onboarding2025/\n",
    "\n",
    "!pip install nipype jedi pypet2bids\n",
    "!apt-get install pigz tree\n",
    "\n",
    "# Install Deno\n",
    "!curl -fsSL https://deno.land/install.sh | sh\n",
    "!export DENO_INSTALL=\"/root/.deno\"\n",
    "!export PATH=\"$DENO_INSTALL/bin:$PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBHDnhIs3Jbx"
   },
   "source": [
    "## Download Phantom ZIP and Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0pLs9KqpYsz",
    "outputId": "67a98270-9462-4b74-f2d7-ee9c4b5a13cb"
   },
   "outputs": [],
   "source": [
    "!if [ ! -f \"PHANTOMS.zip\" ]; then wget -O PHANTOMS.zip https://openneuropet.s3.amazonaws.com/US-sourced-OpenNeuroPET-Phantoms.zip; fi\n",
    "# unzip quietly in either case\n",
    "!unzip -q -o PHANTOMS.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NK8plUDd7SrK"
   },
   "source": [
    "## Install Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRJcdednwHWO"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "check_for_tree = subprocess.run(['which', 'tree'], capture_output=True)\n",
    "if check_for_tree.returncode == 0:\n",
    "    pass\n",
    "else:\n",
    "    import platform\n",
    "    operating_system = platform.system()\n",
    "    if operating_system == 'Linux':\n",
    "        subprocess.run(\"apt-get install tree -y\", shell=True)\n",
    "    elif operating_system == 'Darwin':\n",
    "        subprocess.run(\"brew install tree\", shell=True)\n",
    "    else:\n",
    "        print(\"You're on your own windows user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enkixkXX7wBc"
   },
   "source": [
    "## Check for dcm2niix and install if it's not present.\n",
    "\n",
    "Additionally, we tell pypet2bids where the dcm2niix executable is located at, this is best practice on windows and any sort of virtual environment/notebook as the $PATH variable can be \"wonky\" in the later case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d5d_WQr061H",
    "outputId": "67727f6b-038b-4811-e9db-db9e7fe7c79d"
   },
   "outputs": [],
   "source": [
    "# check for dcm2niix\n",
    "import platform\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "check_dcm2niix = subprocess.run(\"which dcm2niix\", shell=True, capture_output=True)\n",
    "if check_dcm2niix.returncode == 0:\n",
    "    print('dcm2niix is installed')\n",
    "    version = subprocess.run('dcm2niix --version', shell=True, capture_output=True).stdout.decode()\n",
    "    print(version)\n",
    "    # set dcm2niix path as this is running in an ipython notebook\n",
    "    dcm2niix_path = subprocess.run(\"which dcm2niix\", shell=True, capture_output=True)\n",
    "    subprocess.run(f\"dcm2niix4pet --set-dcm2niix-path {dcm2niix_path.stdout.decode()}\", shell=True)\n",
    "else:\n",
    "    print('dcm2niix is not installed')\n",
    "    operating_system = platform.system()\n",
    "    print('Your operating system is detected as '+operating_system)\n",
    "    if operating_system == 'Linux':\n",
    "        dcm2niix_install_dir = Path(\"dcm2niix_install\")\n",
    "        print(f\"dcm2niix_install_dir {dcm2niix_install_dir}\")\n",
    "        if not dcm2niix_install_dir.exists():\n",
    "            os.mkdir(dcm2niix_install_dir)\n",
    "        subprocess.run(\"curl -fLO https://github.com/rordenlab/dcm2niix/releases/download/v1.0.20230411/dcm2niix_lnx.zip\",\n",
    "                         cwd=dcm2niix_install_dir,\n",
    "                         shell=True)\n",
    "        subprocess.run(\"unzip dcm2niix*.zip\",\n",
    "                         shell=True,\n",
    "                         cwd=dcm2niix_install_dir)\n",
    "        if str(dcm2niix_install_dir) not in os.environ.get('PATH', ''):\n",
    "            os.environ['PATH'] += os.pathsep + str(dcm2niix_install_dir.resolve())\n",
    "        # ensure it's on the path\n",
    "        check_dcm2niix_on_path = subprocess.run('dcm2niix --version && which dcm2niix', shell=True, capture_output=True)\n",
    "        check_dcm2niix_on_path.stdout.decode()\n",
    "        print('dcm2niix installed successfully')\n",
    "    elif operating_system == 'Darwin':\n",
    "        subprocess.run(\"brew install dcm2niix\", shell=True)\n",
    "        print('dcm2niix installed successfully')\n",
    "    else:\n",
    "        print(\"You're on your own windows user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpozQIn0m0gx"
   },
   "outputs": [],
   "source": [
    "# import the relevant Python packages\n",
    "import numpy\n",
    "import nibabel\n",
    "import nipype\n",
    "import matplotlib\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fO7qfZhDKXO9"
   },
   "source": [
    "## Setup the bids-validator\n",
    "This is the easiest way to get the bids validator running on a Colab Notebook, from here on out it can be called with `bids-validator()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ex5g0q6Geel",
    "outputId": "5d4ef0cd-a6aa-4e59-e484-f066f7362114"
   },
   "outputs": [],
   "source": [
    "!npm install -g bids-validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgWcLxDP7fkg"
   },
   "source": [
    "## Take a quick look at the raw dicom and ecat data that we've unzipped into this project folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNGqcj0uvzjQ",
    "outputId": "13e51b9a-4aa6-4601-a17b-48cd74510d7e"
   },
   "outputs": [],
   "source": [
    "!tree OpenNeuroPET-Phantoms/sourcedata --filelimit 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaFn08tY8ZOl"
   },
   "source": [
    "## Examine and convert some dicoms obtained from our PHANTOMS.zip with dcm2niix4pet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_No-S4Awa7N",
    "outputId": "6b9b7c02-d52a-41c8-d1c4-96f0676fec6a"
   },
   "outputs": [],
   "source": [
    "!dcm2niix4pet ./OpenNeuroPET-Phantoms/sourcedata/SiemensBiographPETMR-NIMH/AC_TOF -d mynewfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pm3Hgam_1lvR",
    "outputId": "5c633fcb-5931-4ecf-e492-e1ba64105ad8"
   },
   "outputs": [],
   "source": [
    "!tree ./mynewfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDJwP8IqCwfk"
   },
   "source": [
    "I could also add additional information regarding my data using additional flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1xM2hVK1pCF",
    "outputId": "d1c6c089-f4d1-445e-9fcf-087959c05a08"
   },
   "outputs": [],
   "source": [
    "!dcm2niix4pet ./OpenNeuroPET-Phantoms/sourcedata/SiemensBiographPETMR-NIMH/AC_TOF -d mynewfolder2 --kwargs TimeZero=ScanStart Manufacturer=Siemens ManufacturersModelName=Biograph InstitutionName=\"NIH Clinical Center\" BodyPart=Phantom Units=Bq/mL TracerName=none TracerRadionuclide=F18 InjectedRadioactivity=81.24 SpecificRadioactivity=13019.23 ModeOfAdministration=infusion FrameTimesStart=0 AcquisitionMode=\"list mode\" ImageDecayCorrected=true ImageDecayCorrectionTime=0 AttenuationCorrection=MR-corrected FrameDuration=300 FrameTimesStart=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ngARxyhCCZi"
   },
   "source": [
    "Now check if we have created a valid BIDS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvNs8We_CFyn",
    "outputId": "5f844dd9-ec14-4407-e2ef-62bbd80a0315"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "dataset = \"./mynewfolder\"\n",
    "result = subprocess.run(\n",
    "    [\"bids-validator\", dataset, \"--json\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "\n",
    "report = json.loads(result.stdout)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIAU_-u5CHIo"
   },
   "source": [
    "Hmm, what is wrong? Let's look at our file tree again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pHU3qheCLnX",
    "outputId": "c89785e4-6db3-49f8-e1f2-ced6dc1f8dc8"
   },
   "outputs": [],
   "source": [
    "!tree ./mynewfolder2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DovHIg5bCPT7"
   },
   "source": [
    "Basically we have created the appropriate .nii.gz and .json files, but we haven't followed the proper BIDS naming convention!\n",
    "\n",
    "We have done this for you here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UjFFI1pCCOud",
    "outputId": "ec58ca19-8325-44e2-cd9d-729f0840e1f3"
   },
   "outputs": [],
   "source": [
    "!tree ./OpenNeuroPET-Phantoms/sub-SiemensBiographNIMH/ --filelimit 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if the dataset is valid....this time we will validate it differently!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online validation\n",
    "\n",
    "Go to https://bids-standard.github.io/legacy-validator/ and select the folder `OpenNeuroPET-Phantoms` to see if it is valid.\n",
    "(Note we are using the legacy validator since the other one has a runtime issue right now.)\n",
    "\n",
    "You should expect to see some warnings, but the dataset itself is a valid BIDS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrqQYEMWNHPJ"
   },
   "source": [
    "## More advanced BIDS conversion\n",
    "\n",
    "So even though there are libraries that do part of the BIDS conversion for you, there is often some manual work to be done wrt file renaming or adding additional files on top.\n",
    "\n",
    "Converters like EZBids or BIDScoin try to even alleviate this burden.\n",
    "\n",
    "We will play with EZBids!\n",
    "\n",
    "Go to [EZBids](https://brainlife.io/ezbids/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
