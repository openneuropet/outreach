{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMQm1VCgU2Ol"
   },
   "source": [
    "# Brain Imaging Data Structure (BIDS) data conversion tutorial \n",
    "\n",
    "In the following Jupyter notebook, we will introduce you to BIDS basics. You will download some phantom data in neuroimaging formats as they come of a scanner and then work on converting it to BIDS format.\n",
    "Afterwards we will also spend time on how we can utilize data in BIDS format for easy processing of neuroimaging data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NdRZg4Q4wUs"
   },
   "source": [
    "## Collect the Repository and Install all Dependencies\n",
    "This may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XpjaKOjI3VsN",
    "outputId": "41cbac46-7d21-414c-88d2-887903af0610"
   },
   "outputs": [],
   "source": [
    "!if [ -d \"outreach\" ]; then echo \"Repo already cloned.\" && cd outreach && git pull && cd ..; else echo \"Collecting Outreach Repository\" && git clone https://github.com/openneuropet/outreach.git; fi\n",
    "from os.path import basename\n",
    "from os import getcwd\n",
    "if basename(getcwd()) == 'PETBIDS-Onboarding2025':\n",
    "    pass\n",
    "else:\n",
    "    %cd outreach/PETBIDS-Onboarding2025/\n",
    "\n",
    "!pip install nipype jedi pypet2bids\n",
    "!apt-get install pigz tree\n",
    "\n",
    "# Install Deno\n",
    "!curl -fsSL https://deno.land/install.sh | sh\n",
    "!export DENO_INSTALL=\"/root/.deno\"\n",
    "!export PATH=\"$DENO_INSTALL/bin:$PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBHDnhIs3Jbx"
   },
   "source": [
    "## Download Phantom ZIP and Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0pLs9KqpYsz",
    "outputId": "67a98270-9462-4b74-f2d7-ee9c4b5a13cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-02 12:56:25--  https://openneuropet.s3.amazonaws.com/US-sourced-OpenNeuroPET-Phantoms.zip\n",
      "Resolving openneuropet.s3.amazonaws.com (openneuropet.s3.amazonaws.com)... 3.5.30.27, 52.217.9.236, 3.5.8.193, ...\n",
      "Connecting to openneuropet.s3.amazonaws.com (openneuropet.s3.amazonaws.com)|3.5.30.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 115449025 (110M) [application/zip]\n",
      "Saving to: ‘PHANTOMS.zip’\n",
      "\n",
      "PHANTOMS.zip        100%[===================>] 110.10M  90.5MB/s    in 1.2s    \n",
      "\n",
      "2024-06-02 12:56:27 (90.5 MB/s) - ‘PHANTOMS.zip’ saved [115449025/115449025]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!if [ ! -f \"PHANTOMS.zip\" ]; then wget -O PHANTOMS.zip https://openneuropet.s3.amazonaws.com/US-sourced-OpenNeuroPET-Phantoms.zip; fi\n",
    "# unzip quietly in either case\n",
    "!unzip -q -o PHANTOMS.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NK8plUDd7SrK"
   },
   "source": [
    "## Install Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jRJcdednwHWO"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "check_for_tree = subprocess.run(['which', 'tree'], capture_output=True)\n",
    "if check_for_tree.returncode == 0:\n",
    "    pass\n",
    "else:\n",
    "    import platform\n",
    "    operating_system = platform.system()\n",
    "    if operating_system == 'Linux':\n",
    "        subprocess.run(\"apt-get install tree -y\", shell=True)\n",
    "    elif operating_system == 'Darwin':\n",
    "        subprocess.run(\"brew install tree\", shell=True)\n",
    "    else:\n",
    "        print(\"You're on your own windows user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enkixkXX7wBc"
   },
   "source": [
    "## Check for dcm2niix and install if it's not present.\n",
    "\n",
    "Additionally, we tell pypet2bids where the dcm2niix executable is located at, this is best practice on windows and any sort of virtual environment/notebook as the $PATH variable can be \"wonky\" in the later case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d5d_WQr061H",
    "outputId": "67727f6b-038b-4811-e9db-db9e7fe7c79d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcm2niix is installed\n",
      "Chris Rorden's dcm2niiX version v1.0.20230411  (JP2:OpenJPEG) (JP-LS:CharLS) GCC8.4.0 x86-64 (64-bit Linux)\n",
      "v1.0.20230411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for dcm2niix\n",
    "import platform\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "check_dcm2niix = subprocess.run(\"which dcm2niix\", shell=True, capture_output=True)\n",
    "if check_dcm2niix.returncode == 0:\n",
    "    print('dcm2niix is installed')\n",
    "    version = subprocess.run('dcm2niix --version', shell=True, capture_output=True).stdout.decode()\n",
    "    print(version)\n",
    "    # set dcm2niix path as this is running in an ipython notebook\n",
    "    dcm2niix_path = subprocess.run(\"which dcm2niix\", shell=True, capture_output=True)\n",
    "    subprocess.run(f\"dcm2niix4pet --set-dcm2niix-path {dcm2niix_path.stdout.decode()}\", shell=True)\n",
    "else:\n",
    "    print('dcm2niix is not installed')\n",
    "    operating_system = platform.system()\n",
    "    print('Your operating system is detected as '+operating_system)\n",
    "    if operating_system == 'Linux':\n",
    "        dcm2niix_install_dir = Path(\"dcm2niix_install\")\n",
    "        print(f\"dcm2niix_install_dir {dcm2niix_install_dir}\")\n",
    "        if not dcm2niix_install_dir.exists():\n",
    "            os.mkdir(dcm2niix_install_dir)\n",
    "        subprocess.run(\"curl -fLO https://github.com/rordenlab/dcm2niix/releases/download/v1.0.20230411/dcm2niix_lnx.zip\",\n",
    "                         cwd=dcm2niix_install_dir,\n",
    "                         shell=True)\n",
    "        subprocess.run(\"unzip dcm2niix*.zip\",\n",
    "                         shell=True,\n",
    "                         cwd=dcm2niix_install_dir)\n",
    "        if str(dcm2niix_install_dir) not in os.environ.get('PATH', ''):\n",
    "            os.environ['PATH'] += os.pathsep + str(dcm2niix_install_dir.resolve())\n",
    "        # ensure it's on the path\n",
    "        check_dcm2niix_on_path = subprocess.run('dcm2niix --version && which dcm2niix', shell=True, capture_output=True)\n",
    "        check_dcm2niix_on_path.stdout.decode()\n",
    "        print('dcm2niix installed successfully')\n",
    "    elif operating_system == 'Darwin':\n",
    "        subprocess.run(\"brew install dcm2niix\", shell=True)\n",
    "        print('dcm2niix installed successfully')\n",
    "    else:\n",
    "        print(\"You're on your own windows user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lpozQIn0m0gx"
   },
   "outputs": [],
   "source": [
    "# import the relevant Python packages\n",
    "import numpy\n",
    "import nibabel\n",
    "import nipype\n",
    "import matplotlib\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fO7qfZhDKXO9"
   },
   "source": [
    "## Setup the bids-validator\n",
    "This is the easiest way to get the bids validator running on a Colab Notebook, from here on out it can be called with `bids-validator()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ex5g0q6Geel",
    "outputId": "5d4ef0cd-a6aa-4e59-e484-f066f7362114"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mUsage:\u001b[22m   \u001b[95mbids-validator \u001b[33m<\u001b[95m\u001b[95mdataset_directory\u001b[95m\u001b[33m>\u001b[95m\u001b[39m\n",
      "\u001b[1mVersion:\u001b[22m \u001b[33malpha\u001b[39m                             \n",
      "\n",
      "\u001b[1mDescription:\u001b[22m\n",
      "\n",
      "  This tool checks if a dataset in a given directory is compatible with the Brain Imaging Data Structure specification. To learn more about\n",
      "  Brain Imaging Data Structure visit http://bids.neuroimaging.io                                                                           \n",
      "\n",
      "\u001b[1mOptions:\u001b[22m\n",
      "\n",
      "  \u001b[94m-h\u001b[39m, \u001b[94m--help\u001b[39m                    \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Show this help.                                                                                                              \n",
      "  \u001b[94m-V\u001b[39m, \u001b[94m--version\u001b[39m                 \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Show the version number for this program.                                                                                    \n",
      "  \u001b[94m--json\u001b[39m                        \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Output machine readable JSON                                                                                                 \n",
      "  \u001b[94m-s\u001b[39m, \u001b[94m--schema\u001b[39m          \u001b[33m<\u001b[39m\u001b[95mtype\u001b[39m\u001b[33m>\u001b[39m  \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Specify a schema version to use for validation                          (\u001b[1mDefault: \u001b[22m\u001b[32m\"latest\"\u001b[39m)                                  \n",
      "  \u001b[94m-v\u001b[39m, \u001b[94m--verbose\u001b[39m                 \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Log more extensive information about issues                                                                                  \n",
      "  \u001b[94m--ignoreNiftiHeaders\u001b[39m          \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Disregard NIfTI header content during validation                                                                             \n",
      "  \u001b[94m--debug\u001b[39m               \u001b[33m<\u001b[39m\u001b[95mtype\u001b[39m\u001b[33m>\u001b[39m  \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Enable debug output                                                     (\u001b[1mDefault: \u001b[22m\u001b[32m\"ERROR\"\u001b[39m, \u001b[1mValues: \u001b[22m\u001b[32m\"NOTSET\"\u001b[39m, \u001b[32m\"DEBUG\"\u001b[39m, \u001b[32m\"INFO\"\u001b[39m,\n",
      "                                                                                                          \u001b[32m\"WARN\"\u001b[39m, \u001b[32m\"ERROR\"\u001b[39m, \u001b[32m\"CRITICAL\"\u001b[39m)                         \n",
      "  \u001b[94m--filenameMode\u001b[39m                \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Enable filename checks for newline separated filenames read from stdin                                                       \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!npm install -g bids-validatorimport subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgWcLxDP7fkg"
   },
   "source": [
    "## Take a quick look at the raw dicom and ecat data that we've unzipped into this project folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNGqcj0uvzjQ",
    "outputId": "13e51b9a-4aa6-4601-a17b-48cd74510d7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mOpenNeuroPET-Phantoms/sourcedata\u001b[0m\n",
      "├── \u001b[01;34mGeneralElectricAdvance-NIMH\u001b[0m\n",
      "│   ├── \u001b[01;34m2d_unif_lt_ramp\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
      "│   ├── \u001b[01;34m3d375_unif_lt_ramp\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
      "│   ├── \u001b[01;34m3d_unif_lt_ramp\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
      "│   └── \u001b[01;34mlong_trans\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
      "├── \u001b[01;34mGeneralElectricSignaPETMR-NIMH\u001b[0m  [89 entries exceeds filelimit, not opening dir]\n",
      "├── \u001b[01;34mSiemensBiographPETMR-NIMH\u001b[0m\n",
      "│   ├── \u001b[01;34mAC_TOF\u001b[0m  [150 entries exceeds filelimit, not opening dir]\n",
      "│   ├── \u001b[01;34mCT\u001b[0m  [148 entries exceeds filelimit, not opening dir]\n",
      "│   └── \u001b[01;34mNAC\u001b[0m  [148 entries exceeds filelimit, not opening dir]\n",
      "└── \u001b[01;34mSiemensHRRT-JHU\u001b[0m\n",
      "    └── \u001b[00mHoffman.v\u001b[0m\n",
      "\n",
      "11 directories, 1 file\n"
     ]
    }
   ],
   "source": [
    "!tree OpenNeuroPET-Phantoms/sourcedata --filelimit 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaFn08tY8ZOl"
   },
   "source": [
    "## Examine and convert some dicoms obtained from our PHANTOMS.zip with dcm2niix4pet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_No-S4Awa7N",
    "outputId": "6b9b7c02-d52a-41c8-d1c4-96f0676fec6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;20m2024-06-02 12:58:06,092 - pypet2bids - WARNING - dcm2niix found on system path, but dcm2niix path is also set in ~/.pet2bidsconfig. Defaulting to dcm2niix path set in config at /content/outreach/StratNeuro2024/dcm2niix_install/dcm2niix (dcm2niix4pet.py:364)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!dcm2niix4pet ./OpenNeuroPET-Phantoms/sourcedata/SiemensBiographPETMR-NIMH/AC_TOF -d mynewfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pm3Hgam_1lvR",
    "outputId": "5c633fcb-5931-4ecf-e492-e1ba64105ad8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m./mynewfolder\u001b[0m\n",
      "├── \u001b[00mPET_Brain_AC_TOF_resbrain_20210504071146_3.json\u001b[0m\n",
      "└── \u001b[01;31mPET_Brain_AC_TOF_resbrain_20210504071146_3.nii.gz\u001b[0m\n",
      "\n",
      "0 directories, 2 files\n"
     ]
    }
   ],
   "source": [
    "!tree ./mynewfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDJwP8IqCwfk"
   },
   "source": [
    "I could also add additional information regarding my data using additional flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1xM2hVK1pCF",
    "outputId": "d1c6c089-f4d1-445e-9fcf-087959c05a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;20m2024-06-02 12:58:29,156 - pypet2bids - WARNING - dcm2niix found on system path, but dcm2niix path is also set in ~/.pet2bidsconfig. Defaulting to dcm2niix path set in config at /content/outreach/StratNeuro2024/dcm2niix_install/dcm2niix (dcm2niix4pet.py:364)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!dcm2niix4pet ./OpenNeuroPET-Phantoms/sourcedata/SiemensBiographPETMR-NIMH/AC_TOF -d mynewfolder2 --kwargs TimeZero=ScanStart Manufacturer=Siemens ManufacturersModelName=Biograph InstitutionName=\"NIH Clinical Center\" BodyPart=Phantom Units=Bq/mL TracerName=none TracerRadionuclide=F18 InjectedRadioactivity=81.24 SpecificRadioactivity=13019.23 ModeOfAdministration=infusion FrameTimesStart=0 AcquisitionMode=\"list mode\" ImageDecayCorrected=true ImageDecayCorrectionTime=0 AttenuationCorrection=MR-corrected FrameDuration=300 FrameTimesStart=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ngARxyhCCZi"
   },
   "source": [
    "Now check if we have created a valid BIDS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvNs8We_CFyn",
    "outputId": "5f844dd9-ec14-4407-e2ef-62bbd80a0315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\u001b[31m[ERROR] Files with such naming scheme are not part of BIDS specification. This error is most commonly caused by typos in file names that make them not BIDS compatible. Please consult the specification and make sure your files are named correctly. If this is not a file naming issue (for example when including files not yet covered by the BIDS specification) you should include a \".bidsignore\" file in your dataset (see https://github.com/bids-standard/bids-validator#bidsignore for details). Please note that derived (processed) data should be placed in /derivatives folder and source data (such as DICOMS or behavioural logs in proprietary formats) should be placed in the /sourcedata folder. (NOT_INCLUDED)\u001b[39m\n",
      "\n",
      "\t\t./PET_Brain_AC_TOF_resbrain_20210504071146_3.nii.gz\n",
      "\t\t./PET_Brain_AC_TOF_resbrain_20210504071146_3.json\n",
      "\n",
      "\t\t2 more files with the same issue\n",
      "\n",
      "\u001b[36m\tPlease visit https://neurostars.org/search?q=NOT_INCLUDED for existing conversations about this issue.\u001b[39m\n",
      "\n",
      "\n",
      "          \u001b[35mSummary:\u001b[39m                         \u001b[35mAvailable Tasks:\u001b[39m        \u001b[35mAvailable Modalities:\u001b[39m\n",
      "          2 Files, 11.2 MB                                                              \n",
      "          0 - Subjects 1 - Sessions                                                     \n",
      "\n",
      "\u001b[36m\tIf you have any questions, please post on https://neurostars.org/tags/bids.\u001b[39m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "dataset = \"./mynewfolder\"\n",
    "result = subprocess.run(\n",
    "    [\"bids-validator\", dataset, \"--json\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "\n",
    "report = json.loads(result.stdout)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIAU_-u5CHIo"
   },
   "source": [
    "Hmm, what is wrong? Let's look at our file tree again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pHU3qheCLnX",
    "outputId": "c89785e4-6db3-49f8-e1f2-ced6dc1f8dc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m./mynewfolder2\u001b[0m\n",
      "├── \u001b[00mPET_Brain_AC_TOF_resbrain_20210504071146_3.json\u001b[0m\n",
      "└── \u001b[01;31mPET_Brain_AC_TOF_resbrain_20210504071146_3.nii.gz\u001b[0m\n",
      "\n",
      "0 directories, 2 files\n"
     ]
    }
   ],
   "source": [
    "!tree ./mynewfolder2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DovHIg5bCPT7"
   },
   "source": [
    "Basically we have created the appropriate .nii.gz and .json files, but we haven't followed the proper BIDS naming convention!\n",
    "\n",
    "We have done this for you here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UjFFI1pCCOud",
    "outputId": "ec58ca19-8325-44e2-cd9d-729f0840e1f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m./OpenNeuroPET-Phantoms/sub-SiemensBiographNIMH/\u001b[0m\n",
      "└── \u001b[01;34mpet\u001b[0m\n",
      "    ├── \u001b[00msub-SiemensBiographNIMH_pet.json\u001b[0m\n",
      "    └── \u001b[01;31msub-SiemensBiographNIMH_pet.nii.gz\u001b[0m\n",
      "\n",
      "1 directory, 2 files\n"
     ]
    }
   ],
   "source": [
    "!tree ./OpenNeuroPET-Phantoms/sub-SiemensBiographNIMH/ --filelimit 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAh92wi4MkP9"
   },
   "source": [
    "Now let's validate this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5DmpchGbMv2C",
    "outputId": "84afb05f-7445-464d-9707-21c34a29334b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bids_validator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbids_validator\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./OpenNeuroPET-Phantoms/sub-SiemensBiographNIMH/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bids_validator' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = \"./OpenNeuroPET-Phantoms/sub-SiemensBiographNIMH/\"\n",
    "result = subprocess.run(\n",
    "    [\"bids-validator\", dataset, \"--json\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "\n",
    "report = json.loads(result.stdout)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9pyyyWnMwV_"
   },
   "source": [
    "Strictky speaking this only works since we actually have also added a dataset_description file to the file tree. See here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QORvwik6MZyW",
    "outputId": "eaed5554-035c-46fe-8b90-0520c963dafe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m./OpenNeuroPET-Phantoms/\u001b[0m\n",
      "├── \u001b[01;34mcode\u001b[0m\n",
      "│   ├── \u001b[00mmatlab_conversions.m\u001b[0m\n",
      "│   └── \u001b[00mpython_conversions.sh\u001b[0m\n",
      "├── \u001b[00mdataset_description.json\u001b[0m\n",
      "├── \u001b[00mREADME\u001b[0m\n",
      "├── \u001b[01;34msourcedata\u001b[0m\n",
      "│   ├── \u001b[01;34mGeneralElectricAdvance-NIMH\u001b[0m\n",
      "│   │   ├── \u001b[01;34m2d_unif_lt_ramp\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
      "│   │   ├── \u001b[01;34m3d375_unif_lt_ramp\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
      "│   │   ├── \u001b[01;34m3d_unif_lt_ramp\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
      "│   │   └── \u001b[01;34mlong_trans\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
      "│   ├── \u001b[01;34mGeneralElectricSignaPETMR-NIMH\u001b[0m  [89 entries exceeds filelimit, not opening dir]\n",
      "│   ├── \u001b[01;34mSiemensBiographPETMR-NIMH\u001b[0m\n",
      "│   │   ├── \u001b[01;34mAC_TOF\u001b[0m  [150 entries exceeds filelimit, not opening dir]\n",
      "│   │   ├── \u001b[01;34mCT\u001b[0m  [148 entries exceeds filelimit, not opening dir]\n",
      "│   │   └── \u001b[01;34mNAC\u001b[0m  [148 entries exceeds filelimit, not opening dir]\n",
      "│   └── \u001b[01;34mSiemensHRRT-JHU\u001b[0m\n",
      "│       └── \u001b[00mHoffman.v\u001b[0m\n",
      "├── \u001b[01;34msub-GeneralElectricAdvanceLongNIMH\u001b[0m\n",
      "│   └── \u001b[01;34mpet\u001b[0m\n",
      "│       ├── \u001b[00msub-GeneralElectricAdvanceLongNIMH_pet.json\u001b[0m\n",
      "│       └── \u001b[01;31msub-GeneralElectricAdvanceLongNIMH_pet.nii.gz\u001b[0m\n",
      "├── \u001b[01;34msub-GeneralElectricAdvanceNIMH\u001b[0m\n",
      "│   └── \u001b[01;34mpet\u001b[0m\n",
      "│       ├── \u001b[00msub-GeneralElectricAdvanceNIMH_pet.json\u001b[0m\n",
      "│       └── \u001b[01;31msub-GeneralElectricAdvanceNIMH_pet.nii.gz\u001b[0m\n",
      "├── \u001b[01;34msub-GeneralElectricSignaNIMH\u001b[0m\n",
      "│   └── \u001b[01;34mpet\u001b[0m\n",
      "│       ├── \u001b[00msub-GeneralElectricSignaNIMH_pet.json\u001b[0m\n",
      "│       └── \u001b[01;31msub-GeneralElectricSignaNIMH_pet.nii.gz\u001b[0m\n",
      "├── \u001b[01;34msub-SiemensBiographNIMH\u001b[0m\n",
      "│   └── \u001b[01;34mpet\u001b[0m\n",
      "│       ├── \u001b[00msub-SiemensBiographNIMH_pet.json\u001b[0m\n",
      "│       └── \u001b[01;31msub-SiemensBiographNIMH_pet.nii.gz\u001b[0m\n",
      "└── \u001b[01;34msub-SiemensHRRTNRU\u001b[0m\n",
      "    └── \u001b[01;34mpet\u001b[0m\n",
      "        ├── \u001b[00msub-SiemensHRRTNRU_pet.json\u001b[0m\n",
      "        └── \u001b[01;31msub-SiemensHRRTNRU_pet.nii.gz\u001b[0m\n",
      "\n",
      "23 directories, 15 files\n"
     ]
    }
   ],
   "source": [
    "!tree ./OpenNeuroPET-Phantoms/ --filelimit 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrqQYEMWNHPJ"
   },
   "source": [
    "So even though there are libraries that do part of the BIDS conversion for you, there is often some manual work to be done wrt file renaming or adding additional files on top.\n",
    "\n",
    "Converters like EZBids or BIDScoin try to even alleviate this burden.\n",
    "\n",
    "We will play with EZBids!\n",
    "\n",
    "Go to [EZBids](https://brainlife.io/ezbids/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nifreeze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
