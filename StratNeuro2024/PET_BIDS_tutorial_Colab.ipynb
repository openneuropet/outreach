{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Brain Imaging Data Structure (BIDS) tutorial at Stratneuro 2024\n",
        "\n",
        "In the following Jupyter notebook, we will introduce you to BIDS basics. You will download some phantom data in neuroimaging formats as they come of a scanner and then work on converting it to BIDS format.\n",
        "Afterwards we will also spend time on how we can utilize data in BIDS format for easy processing of neuroimaging data.\n",
        "\n",
        "\n",
        "Other practical details for the day can be found [here](https://news.ki.se/calendar/stratneuro-retreat-2024-exclusive-day-for-phd-students)."
      ],
      "metadata": {
        "id": "kMQm1VCgU2Ol"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NdRZg4Q4wUs"
      },
      "source": [
        "## Collect the Repository and Install all Dependencies\n",
        "This may take some time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpjaKOjI3VsN",
        "outputId": "41cbac46-7d21-414c-88d2-887903af0610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Outreach Repository\n",
            "Cloning into 'outreach'...\n",
            "remote: Enumerating objects: 1345, done.\u001b[K\n",
            "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 1345 (delta 98), reused 65 (delta 60), pack-reused 1210\u001b[K\n",
            "Receiving objects: 100% (1345/1345), 60.54 MiB | 21.80 MiB/s, done.\n",
            "Resolving deltas: 100% (741/741), done.\n",
            "/content/outreach/StratNeuro2024\n",
            "Collecting nipype\n",
            "  Downloading nipype-1.8.6-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jedi\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypet2bids\n",
            "  Downloading pypet2bids-1.3.9-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from nipype) (8.1.7)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from nipype) (3.3)\n",
            "Requirement already satisfied: nibabel>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from nipype) (4.0.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from nipype) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nipype) (24.0)\n",
            "Collecting prov>=1.5.2 (from nipype)\n",
            "  Downloading prov-2.0.0-py3-none-any.whl (421 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype) (2.8.2)\n",
            "Collecting rdflib>=5.0.0 (from nipype)\n",
            "  Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from nipype) (1.11.4)\n",
            "Collecting simplejson>=3.8.0 (from nipype)\n",
            "  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traits!=5.0,<6.4,>=4.6 (from nipype)\n",
            "  Downloading traits-6.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype) (3.14.0)\n",
            "Collecting etelemetry>=0.2.0 (from nipype)\n",
            "  Downloading etelemetry-0.3.1-py3-none-any.whl (6.4 kB)\n",
            "Collecting looseversion (from nipype)\n",
            "  Downloading looseversion-1.3.0-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi) (0.8.4)\n",
            "Requirement already satisfied: joblib<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pypet2bids) (1.4.2)\n",
            "Collecting json-maj<0.0.9,>=0.0.8 (from pypet2bids)\n",
            "  Downloading json_maj-0.0.8-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: openpyxl<4.0.0,>=3.0.9 in /usr/local/lib/python3.10/dist-packages (from pypet2bids) (3.1.2)\n",
            "Collecting pandas<2.0.0,>=1.4.4 (from pypet2bids)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydicom<3.0.0,>=2.2.2 (from pypet2bids)\n",
            "  Downloading pydicom-2.4.4-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing<4.0.0,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from pypet2bids) (3.1.2)\n",
            "Collecting python-dotenv<0.20.0,>=0.19.1 (from pypet2bids)\n",
            "  Downloading python_dotenv-0.19.2-py2.py3-none-any.whl (17 kB)\n",
            "Collecting pyxlsb<2.0.0,>=1.0.9 (from pypet2bids)\n",
            "  Downloading pyxlsb-1.0.10-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: six<2.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pypet2bids) (1.16.0)\n",
            "Requirement already satisfied: toml>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from pypet2bids) (0.10.2)\n",
            "Requirement already satisfied: xlrd<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pypet2bids) (2.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from etelemetry>=0.2.0->nipype) (2.31.0)\n",
            "Collecting ci-info>=0.2 (from etelemetry>=0.2.0->nipype)\n",
            "  Downloading ci_info-0.3.0-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel>=2.1.0->nipype) (67.7.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl<4.0.0,>=3.0.9->pypet2bids) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.4.4->pypet2bids) (2023.4)\n",
            "Requirement already satisfied: lxml>=3.3.5 in /usr/local/lib/python3.10/dist-packages (from prov>=1.5.2->nipype) (4.9.4)\n",
            "Collecting isodate<0.7.0,>=0.6.0 (from rdflib>=5.0.0->nipype)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->etelemetry>=0.2.0->nipype) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->etelemetry>=0.2.0->nipype) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->etelemetry>=0.2.0->nipype) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->etelemetry>=0.2.0->nipype) (2024.2.2)\n",
            "Installing collected packages: pyxlsb, looseversion, traits, simplejson, python-dotenv, pydicom, json-maj, jedi, isodate, ci-info, rdflib, pandas, etelemetry, pypet2bids, prov, nipype\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ci-info-0.3.0 etelemetry-0.3.1 isodate-0.6.1 jedi-0.19.1 json-maj-0.0.8 looseversion-1.3.0 nipype-1.8.6 pandas-1.5.3 prov-2.0.0 pydicom-2.4.4 pypet2bids-1.3.9 python-dotenv-0.19.2 pyxlsb-1.0.10 rdflib-7.0.0 simplejson-3.19.2 traits-6.3.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  pigz tree\n",
            "0 upgraded, 2 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 112 kB of archives.\n",
            "After this operation, 278 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pigz amd64 2.6-1 [63.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 112 kB in 0s (233 kB/s)\n",
            "Selecting previously unselected package pigz.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../archives/pigz_2.6-1_amd64.deb ...\n",
            "Unpacking pigz (2.6-1) ...\n",
            "Selecting previously unselected package tree.\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Setting up pigz (2.6-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "############################################################################################# 100.0%\n",
            "Archive:  /root/.deno/bin/deno.zip\n",
            "  inflating: /root/.deno/bin/deno    \n",
            "Deno was installed successfully to /root/.deno/bin/deno\n",
            "Manually add the directory to your $HOME/.bashrc (or similar)\n",
            "  export DENO_INSTALL=\"/root/.deno\"\n",
            "  export PATH=\"$DENO_INSTALL/bin:$PATH\"\n",
            "Run '/root/.deno/bin/deno --help' to get started\n",
            "\n",
            "Stuck? Join our Discord https://discord.gg/deno\n"
          ]
        }
      ],
      "source": [
        "!if [ -d \"outreach\" ]; then echo \"Repo already cloned.\" && cd outreach && git pull && cd ..; else echo \"Collecting Outreach Repository\" && git clone https://github.com/openneuropet/outreach.git; fi\n",
        "from os.path import basename\n",
        "from os import getcwd\n",
        "if basename(getcwd()) == 'StratNeuro2024':\n",
        "    pass\n",
        "else:\n",
        "    %cd outreach/StratNeuro2024/\n",
        "\n",
        "!pip install nipype jedi pypet2bids\n",
        "!apt-get install pigz tree\n",
        "\n",
        "# Install Deno\n",
        "!curl -fsSL https://deno.land/install.sh | sh\n",
        "!export DENO_INSTALL=\"/root/.deno\"\n",
        "!export PATH=\"$DENO_INSTALL/bin:$PATH\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBHDnhIs3Jbx"
      },
      "source": [
        "## Download Phantom ZIP and Extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0pLs9KqpYsz",
        "outputId": "67a98270-9462-4b74-f2d7-ee9c4b5a13cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-02 12:56:25--  https://openneuropet.s3.amazonaws.com/US-sourced-OpenNeuroPET-Phantoms.zip\n",
            "Resolving openneuropet.s3.amazonaws.com (openneuropet.s3.amazonaws.com)... 3.5.30.27, 52.217.9.236, 3.5.8.193, ...\n",
            "Connecting to openneuropet.s3.amazonaws.com (openneuropet.s3.amazonaws.com)|3.5.30.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 115449025 (110M) [application/zip]\n",
            "Saving to: ‘PHANTOMS.zip’\n",
            "\n",
            "PHANTOMS.zip        100%[===================>] 110.10M  90.5MB/s    in 1.2s    \n",
            "\n",
            "2024-06-02 12:56:27 (90.5 MB/s) - ‘PHANTOMS.zip’ saved [115449025/115449025]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!if [ ! -f \"PHANTOMS.zip\" ]; then wget -O PHANTOMS.zip https://openneuropet.s3.amazonaws.com/US-sourced-OpenNeuroPET-Phantoms.zip; fi\n",
        "# unzip quietly in either case\n",
        "!unzip -q -o PHANTOMS.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK8plUDd7SrK"
      },
      "source": [
        "## Install Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jRJcdednwHWO"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "check_for_tree = subprocess.run(['which', 'tree'], capture_output=True)\n",
        "if check_for_tree.returncode == 0:\n",
        "    pass\n",
        "else:\n",
        "    import platform\n",
        "    operating_system = platform.system()\n",
        "    if operating_system == 'Linux':\n",
        "        subprocess.run(\"apt-get install tree -y\", shell=True)\n",
        "    elif operating_system == 'Darwin':\n",
        "        subprocess.run(\"brew install tree\", shell=True)\n",
        "    else:\n",
        "        print(\"You're on your own windows user.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enkixkXX7wBc"
      },
      "source": [
        "## Check for dcm2niix and install if it's not present.\n",
        "\n",
        "Additionally, we tell pypet2bids where the dcm2niix executable is located at, this is best practice on windows and any sort of virtual environment/notebook as the $PATH variable can be \"wonky\" in the later case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d5d_WQr061H",
        "outputId": "67727f6b-038b-4811-e9db-db9e7fe7c79d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcm2niix is installed\n",
            "Chris Rorden's dcm2niiX version v1.0.20230411  (JP2:OpenJPEG) (JP-LS:CharLS) GCC8.4.0 x86-64 (64-bit Linux)\n",
            "v1.0.20230411\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# check for dcm2niix\n",
        "import platform\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "check_dcm2niix = subprocess.run(\"which dcm2niix\", shell=True, capture_output=True)\n",
        "if check_dcm2niix.returncode == 0:\n",
        "    print('dcm2niix is installed')\n",
        "    version = subprocess.run('dcm2niix --version', shell=True, capture_output=True).stdout.decode()\n",
        "    print(version)\n",
        "    # set dcm2niix path as this is running in an ipython notebook\n",
        "    dcm2niix_path = subprocess.run(\"which dcm2niix\", shell=True, capture_output=True)\n",
        "    subprocess.run(f\"dcm2niix4pet --set-dcm2niix-path {dcm2niix_path.stdout.decode()}\", shell=True)\n",
        "else:\n",
        "    print('dcm2niix is not installed')\n",
        "    operating_system = platform.system()\n",
        "    print('Your operating system is detected as '+operating_system)\n",
        "    if operating_system == 'Linux':\n",
        "        dcm2niix_install_dir = Path(\"dcm2niix_install\")\n",
        "        print(f\"dcm2niix_install_dir {dcm2niix_install_dir}\")\n",
        "        if not dcm2niix_install_dir.exists():\n",
        "            os.mkdir(dcm2niix_install_dir)\n",
        "        subprocess.run(\"curl -fLO https://github.com/rordenlab/dcm2niix/releases/download/v1.0.20230411/dcm2niix_lnx.zip\",\n",
        "                         cwd=dcm2niix_install_dir,\n",
        "                         shell=True)\n",
        "        subprocess.run(\"unzip dcm2niix*.zip\",\n",
        "                         shell=True,\n",
        "                         cwd=dcm2niix_install_dir)\n",
        "        if str(dcm2niix_install_dir) not in os.environ.get('PATH', ''):\n",
        "            os.environ['PATH'] += os.pathsep + str(dcm2niix_install_dir.resolve())\n",
        "        # ensure it's on the path\n",
        "        check_dcm2niix_on_path = subprocess.run('dcm2niix --version && which dcm2niix', shell=True, capture_output=True)\n",
        "        check_dcm2niix_on_path.stdout.decode()\n",
        "        print('dcm2niix installed successfully')\n",
        "    elif operating_system == 'Darwin':\n",
        "        subprocess.run(\"brew install dcm2niix\", shell=True)\n",
        "        print('dcm2niix installed successfully')\n",
        "    else:\n",
        "        print(\"You're on your own windows user.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lpozQIn0m0gx"
      },
      "outputs": [],
      "source": [
        "# import the relevant Python packages\n",
        "import numpy\n",
        "import nibabel\n",
        "import nipype\n",
        "import matplotlib\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO7qfZhDKXO9"
      },
      "source": [
        "## Setup the bids-validator\n",
        "This is the easiest way to get the bids validator running on a Colab Notebook, from here on out it can be called with `bids-validator()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ex5g0q6Geel",
        "outputId": "5d4ef0cd-a6aa-4e59-e484-f066f7362114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mUsage:\u001b[22m   \u001b[95mbids-validator \u001b[33m<\u001b[95m\u001b[95mdataset_directory\u001b[95m\u001b[33m>\u001b[95m\u001b[39m\n",
            "\u001b[1mVersion:\u001b[22m \u001b[33malpha\u001b[39m                             \n",
            "\n",
            "\u001b[1mDescription:\u001b[22m\n",
            "\n",
            "  This tool checks if a dataset in a given directory is compatible with the Brain Imaging Data Structure specification. To learn more about\n",
            "  Brain Imaging Data Structure visit http://bids.neuroimaging.io                                                                           \n",
            "\n",
            "\u001b[1mOptions:\u001b[22m\n",
            "\n",
            "  \u001b[94m-h\u001b[39m, \u001b[94m--help\u001b[39m                    \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Show this help.                                                                                                              \n",
            "  \u001b[94m-V\u001b[39m, \u001b[94m--version\u001b[39m                 \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Show the version number for this program.                                                                                    \n",
            "  \u001b[94m--json\u001b[39m                        \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Output machine readable JSON                                                                                                 \n",
            "  \u001b[94m-s\u001b[39m, \u001b[94m--schema\u001b[39m          \u001b[33m<\u001b[39m\u001b[95mtype\u001b[39m\u001b[33m>\u001b[39m  \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Specify a schema version to use for validation                          (\u001b[1mDefault: \u001b[22m\u001b[32m\"latest\"\u001b[39m)                                  \n",
            "  \u001b[94m-v\u001b[39m, \u001b[94m--verbose\u001b[39m                 \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Log more extensive information about issues                                                                                  \n",
            "  \u001b[94m--ignoreNiftiHeaders\u001b[39m          \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Disregard NIfTI header content during validation                                                                             \n",
            "  \u001b[94m--debug\u001b[39m               \u001b[33m<\u001b[39m\u001b[95mtype\u001b[39m\u001b[33m>\u001b[39m  \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Enable debug output                                                     (\u001b[1mDefault: \u001b[22m\u001b[32m\"ERROR\"\u001b[39m, \u001b[1mValues: \u001b[22m\u001b[32m\"NOTSET\"\u001b[39m, \u001b[32m\"DEBUG\"\u001b[39m, \u001b[32m\"INFO\"\u001b[39m,\n",
            "                                                                                                          \u001b[32m\"WARN\"\u001b[39m, \u001b[32m\"ERROR\"\u001b[39m, \u001b[32m\"CRITICAL\"\u001b[39m)                         \n",
            "  \u001b[94m--filenameMode\u001b[39m                \u001b[31m\u001b[1m-\u001b[22m\u001b[39m Enable filename checks for newline separated filenames read from stdin                                                       \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "def bids_validator(path_to_dataset='.'):\n",
        "  validator = subprocess.run(f\"/root/.deno/bin/deno run --allow-read --allow-env https://deno.land/x/bids_validator/bids-validator.ts {path_to_dataset}\", shell=True, capture_output=True, text=True)\n",
        "  print(validator.stdout)\n",
        "\n",
        "bids_validator('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgWcLxDP7fkg"
      },
      "source": [
        "## Take a quick look at the raw dicom and ecat data that we've unzipped into this project folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNGqcj0uvzjQ",
        "outputId": "13e51b9a-4aa6-4601-a17b-48cd74510d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34mOpenNeuroPET-Phantoms/sourcedata\u001b[0m\n",
            "├── \u001b[01;34mGeneralElectricAdvance-NIMH\u001b[0m\n",
            "│   ├── \u001b[01;34m2d_unif_lt_ramp\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
            "│   ├── \u001b[01;34m3d375_unif_lt_ramp\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
            "│   ├── \u001b[01;34m3d_unif_lt_ramp\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
            "│   └── \u001b[01;34mlong_trans\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
            "├── \u001b[01;34mGeneralElectricSignaPETMR-NIMH\u001b[0m  [89 entries exceeds filelimit, not opening dir]\n",
            "├── \u001b[01;34mSiemensBiographPETMR-NIMH\u001b[0m\n",
            "│   ├── \u001b[01;34mAC_TOF\u001b[0m  [150 entries exceeds filelimit, not opening dir]\n",
            "│   ├── \u001b[01;34mCT\u001b[0m  [148 entries exceeds filelimit, not opening dir]\n",
            "│   └── \u001b[01;34mNAC\u001b[0m  [148 entries exceeds filelimit, not opening dir]\n",
            "└── \u001b[01;34mSiemensHRRT-JHU\u001b[0m\n",
            "    └── \u001b[00mHoffman.v\u001b[0m\n",
            "\n",
            "11 directories, 1 file\n"
          ]
        }
      ],
      "source": [
        "!tree OpenNeuroPET-Phantoms/sourcedata --filelimit 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaFn08tY8ZOl"
      },
      "source": [
        "## Examine and convert some dicoms obtained from our PHANTOMS.zip with dcm2niix4pet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_No-S4Awa7N",
        "outputId": "6b9b7c02-d52a-41c8-d1c4-96f0676fec6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33;20m2024-06-02 12:58:06,092 - pypet2bids - WARNING - dcm2niix found on system path, but dcm2niix path is also set in ~/.pet2bidsconfig. Defaulting to dcm2niix path set in config at /content/outreach/StratNeuro2024/dcm2niix_install/dcm2niix (dcm2niix4pet.py:364)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!dcm2niix4pet ./OpenNeuroPET-Phantoms/sourcedata/SiemensBiographPETMR-NIMH/AC_TOF -d mynewfolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm3Hgam_1lvR",
        "outputId": "5c633fcb-5931-4ecf-e492-e1ba64105ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m./mynewfolder\u001b[0m\n",
            "├── \u001b[00mPET_Brain_AC_TOF_resbrain_20210504071146_3.json\u001b[0m\n",
            "└── \u001b[01;31mPET_Brain_AC_TOF_resbrain_20210504071146_3.nii.gz\u001b[0m\n",
            "\n",
            "0 directories, 2 files\n"
          ]
        }
      ],
      "source": [
        "!tree ./mynewfolder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I could also add additional information regarding my data using additional flags:"
      ],
      "metadata": {
        "id": "JDJwP8IqCwfk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1xM2hVK1pCF",
        "outputId": "d1c6c089-f4d1-445e-9fcf-087959c05a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33;20m2024-06-02 12:58:29,156 - pypet2bids - WARNING - dcm2niix found on system path, but dcm2niix path is also set in ~/.pet2bidsconfig. Defaulting to dcm2niix path set in config at /content/outreach/StratNeuro2024/dcm2niix_install/dcm2niix (dcm2niix4pet.py:364)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!dcm2niix4pet ./OpenNeuroPET-Phantoms/sourcedata/SiemensBiographPETMR-NIMH/AC_TOF -d mynewfolder2 --kwargs TimeZero=ScanStart Manufacturer=Siemens ManufacturersModelName=Biograph InstitutionName=\"NIH Clinical Center\" BodyPart=Phantom Units=Bq/mL TracerName=none TracerRadionuclide=F18 InjectedRadioactivity=81.24 SpecificRadioactivity=13019.23 ModeOfAdministration=infusion FrameTimesStart=0 AcquisitionMode=\"list mode\" ImageDecayCorrected=true ImageDecayCorrectionTime=0 AttenuationCorrection=MR-corrected FrameDuration=300 FrameTimesStart=0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now check if we have created a valid BIDS dataset"
      ],
      "metadata": {
        "id": "6ngARxyhCCZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bids_validator('./mynewfolder2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvNs8We_CFyn",
        "outputId": "5f844dd9-ec14-4407-e2ef-62bbd80a0315"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\u001b[31m[ERROR] Files with such naming scheme are not part of BIDS specification. This error is most commonly caused by typos in file names that make them not BIDS compatible. Please consult the specification and make sure your files are named correctly. If this is not a file naming issue (for example when including files not yet covered by the BIDS specification) you should include a \".bidsignore\" file in your dataset (see https://github.com/bids-standard/bids-validator#bidsignore for details). Please note that derived (processed) data should be placed in /derivatives folder and source data (such as DICOMS or behavioural logs in proprietary formats) should be placed in the /sourcedata folder. (NOT_INCLUDED)\u001b[39m\n",
            "\n",
            "\t\t./PET_Brain_AC_TOF_resbrain_20210504071146_3.nii.gz\n",
            "\t\t./PET_Brain_AC_TOF_resbrain_20210504071146_3.json\n",
            "\n",
            "\t\t2 more files with the same issue\n",
            "\n",
            "\u001b[36m\tPlease visit https://neurostars.org/search?q=NOT_INCLUDED for existing conversations about this issue.\u001b[39m\n",
            "\n",
            "\n",
            "          \u001b[35mSummary:\u001b[39m                         \u001b[35mAvailable Tasks:\u001b[39m        \u001b[35mAvailable Modalities:\u001b[39m\n",
            "          2 Files, 11.2 MB                                                              \n",
            "          0 - Subjects 1 - Sessions                                                     \n",
            "\n",
            "\u001b[36m\tIf you have any questions, please post on https://neurostars.org/tags/bids.\u001b[39m\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmm, what is wrong? Let's look at our file tree again."
      ],
      "metadata": {
        "id": "tIAU_-u5CHIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tree ./mynewfolder2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pHU3qheCLnX",
        "outputId": "c89785e4-6db3-49f8-e1f2-ced6dc1f8dc8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m./mynewfolder2\u001b[0m\n",
            "├── \u001b[00mPET_Brain_AC_TOF_resbrain_20210504071146_3.json\u001b[0m\n",
            "└── \u001b[01;31mPET_Brain_AC_TOF_resbrain_20210504071146_3.nii.gz\u001b[0m\n",
            "\n",
            "0 directories, 2 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basically we have created the appropriate .nii.gz and .json files, but we haven't followed the proper BIDS naming convention!\n",
        "\n",
        "We have done this for you here:"
      ],
      "metadata": {
        "id": "DovHIg5bCPT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tree ./OpenNeuroPET-Phantoms/sub-SiemensBiographNIMH/ --filelimit 15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjFFI1pCCOud",
        "outputId": "ec58ca19-8325-44e2-cd9d-729f0840e1f3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m./OpenNeuroPET-Phantoms/sub-SiemensBiographNIMH/\u001b[0m\n",
            "└── \u001b[01;34mpet\u001b[0m\n",
            "    ├── \u001b[00msub-SiemensBiographNIMH_pet.json\u001b[0m\n",
            "    └── \u001b[01;31msub-SiemensBiographNIMH_pet.nii.gz\u001b[0m\n",
            "\n",
            "1 directory, 2 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's validate this.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZAh92wi4MkP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bids_validator('./OpenNeuroPET-Phantoms/sub-SiemensBiographNIMH/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DmpchGbMv2C",
        "outputId": "84afb05f-7445-464d-9707-21c34a29334b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mThis dataset appears to be BIDS compatible.\u001b[39m\n",
            "\n",
            "          \u001b[35mSummary:\u001b[39m                         \u001b[35mAvailable Tasks:\u001b[39m        \u001b[35mAvailable Modalities:\u001b[39m\n",
            "          2 Files, 11.3 MB                                                              \n",
            "          1 - Subjects 1 - Sessions                                                     \n",
            "\n",
            "\u001b[36m\tIf you have any questions, please post on https://neurostars.org/tags/bids.\u001b[39m\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strictky speaking this only works since we actually have also added a dataset_description file to the file tree. See here:"
      ],
      "metadata": {
        "id": "I9pyyyWnMwV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tree ./OpenNeuroPET-Phantoms/ --filelimit 15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QORvwik6MZyW",
        "outputId": "eaed5554-035c-46fe-8b90-0520c963dafe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m./OpenNeuroPET-Phantoms/\u001b[0m\n",
            "├── \u001b[01;34mcode\u001b[0m\n",
            "│   ├── \u001b[00mmatlab_conversions.m\u001b[0m\n",
            "│   └── \u001b[00mpython_conversions.sh\u001b[0m\n",
            "├── \u001b[00mdataset_description.json\u001b[0m\n",
            "├── \u001b[00mREADME\u001b[0m\n",
            "├── \u001b[01;34msourcedata\u001b[0m\n",
            "│   ├── \u001b[01;34mGeneralElectricAdvance-NIMH\u001b[0m\n",
            "│   │   ├── \u001b[01;34m2d_unif_lt_ramp\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
            "│   │   ├── \u001b[01;34m3d375_unif_lt_ramp\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
            "│   │   ├── \u001b[01;34m3d_unif_lt_ramp\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
            "│   │   └── \u001b[01;34mlong_trans\u001b[0m  [35 entries exceeds filelimit, not opening dir]\n",
            "│   ├── \u001b[01;34mGeneralElectricSignaPETMR-NIMH\u001b[0m  [89 entries exceeds filelimit, not opening dir]\n",
            "│   ├── \u001b[01;34mSiemensBiographPETMR-NIMH\u001b[0m\n",
            "│   │   ├── \u001b[01;34mAC_TOF\u001b[0m  [150 entries exceeds filelimit, not opening dir]\n",
            "│   │   ├── \u001b[01;34mCT\u001b[0m  [148 entries exceeds filelimit, not opening dir]\n",
            "│   │   └── \u001b[01;34mNAC\u001b[0m  [148 entries exceeds filelimit, not opening dir]\n",
            "│   └── \u001b[01;34mSiemensHRRT-JHU\u001b[0m\n",
            "│       └── \u001b[00mHoffman.v\u001b[0m\n",
            "├── \u001b[01;34msub-GeneralElectricAdvanceLongNIMH\u001b[0m\n",
            "│   └── \u001b[01;34mpet\u001b[0m\n",
            "│       ├── \u001b[00msub-GeneralElectricAdvanceLongNIMH_pet.json\u001b[0m\n",
            "│       └── \u001b[01;31msub-GeneralElectricAdvanceLongNIMH_pet.nii.gz\u001b[0m\n",
            "├── \u001b[01;34msub-GeneralElectricAdvanceNIMH\u001b[0m\n",
            "│   └── \u001b[01;34mpet\u001b[0m\n",
            "│       ├── \u001b[00msub-GeneralElectricAdvanceNIMH_pet.json\u001b[0m\n",
            "│       └── \u001b[01;31msub-GeneralElectricAdvanceNIMH_pet.nii.gz\u001b[0m\n",
            "├── \u001b[01;34msub-GeneralElectricSignaNIMH\u001b[0m\n",
            "│   └── \u001b[01;34mpet\u001b[0m\n",
            "│       ├── \u001b[00msub-GeneralElectricSignaNIMH_pet.json\u001b[0m\n",
            "│       └── \u001b[01;31msub-GeneralElectricSignaNIMH_pet.nii.gz\u001b[0m\n",
            "├── \u001b[01;34msub-SiemensBiographNIMH\u001b[0m\n",
            "│   └── \u001b[01;34mpet\u001b[0m\n",
            "│       ├── \u001b[00msub-SiemensBiographNIMH_pet.json\u001b[0m\n",
            "│       └── \u001b[01;31msub-SiemensBiographNIMH_pet.nii.gz\u001b[0m\n",
            "└── \u001b[01;34msub-SiemensHRRTNRU\u001b[0m\n",
            "    └── \u001b[01;34mpet\u001b[0m\n",
            "        ├── \u001b[00msub-SiemensHRRTNRU_pet.json\u001b[0m\n",
            "        └── \u001b[01;31msub-SiemensHRRTNRU_pet.nii.gz\u001b[0m\n",
            "\n",
            "23 directories, 15 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So even though there are libraries that do part of the BIDS conversion for you, there is often some manual work to be done wrt file renaming or adding additional files on top.\n",
        "\n",
        "Converters like EZBids or BIDScoin try to even alleviate this burden.\n",
        "\n",
        "We will play with EZBids!\n",
        "\n",
        "Go to [EZBids](https://brainlife.io/ezbids/)"
      ],
      "metadata": {
        "id": "mrqQYEMWNHPJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq5V5Gtu5w0b"
      },
      "source": [
        "## Running processing pipelines on BIDS data\n",
        "Note, run this only only if freesurfer is installed (you need to run the cells below)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install FreeSurfer\n",
        "Note, this is only necessary if you want to actually run the pipelines below\n"
      ],
      "metadata": {
        "id": "s4t8wxgRoiIm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBoaIuC9NjPz",
        "outputId": "1cfa4567-0349-4421-db42-1fc4b3e8126c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-02 11:07:23--  https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.4.1/freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz\n",
            "Resolving surfer.nmr.mgh.harvard.edu (surfer.nmr.mgh.harvard.edu)... 132.183.1.43\n",
            "Connecting to surfer.nmr.mgh.harvard.edu (surfer.nmr.mgh.harvard.edu)|132.183.1.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9484461482 (8.8G) [application/x-gzip]\n",
            "Saving to: ‘freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz’\n",
            "\n",
            "freesurfer-linux-ub 100%[===================>]   8.83G  63.9MB/s    in 2m 25s  \n",
            "\n",
            "2024-06-02 11:09:48 (62.4 MB/s) - ‘freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz’ saved [9484461482/9484461482]\n",
            "\n",
            "\n",
            "real\t3m43.312s\n",
            "user\t2m24.130s\n",
            "sys\t1m15.407s\n",
            "/content/outreach/StratNeuro2024/freesurfer/bin/:/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n",
            "mri_coreg freesurfer 7.4.1\n"
          ]
        }
      ],
      "source": [
        "# Download freesurfer 7.4.1\n",
        "!wget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.4.1/freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz\n",
        "!if [ -f freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz ]; then time pigz -dc freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz | tar xf -; fi\n",
        "import os, sys\n",
        "# append freesurfer to system path\n",
        "freesurfer_path = os.path.join(os.getcwd(), 'freesurfer/bin/')\n",
        "os.getenv('PATH')\n",
        "if freesurfer_path not in os.environ['PATH']:\n",
        "  os.environ['PATH'] = freesurfer_path + ':' + os.getenv('PATH')\n",
        "freesurfer_home = os.environ['FREESURFER_HOME'] = os.path.join(os.getcwd(), 'freesurfer')\n",
        "subjects_dir = os.environ['SUBJECTS_DIR'] = os.path.join(os.getcwd(), 'freesurfer', 'subjects')\n",
        "\n",
        "def set_global_variables():\n",
        "    global freesurfer_home\n",
        "    global subjects_dir\n",
        "\n",
        "set_global_variables()\n",
        "\n",
        "# copy license file into freesurfer home\n",
        "!cp license.txt $FREESURFER_HOME/\n",
        "!echo $PATH\n",
        "!mri_coreg --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG7EVprcYRgh",
        "outputId": "bcec84d1-0f8b-490a-8336-0bfd64b8b97a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/outreach/StratNeuro2024/freesurfer\n"
          ]
        }
      ],
      "source": [
        "print(freesurfer_home)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDGo8KQ51uHe"
      },
      "outputs": [],
      "source": [
        "!mkdir PETprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrECWZDq1xPB"
      },
      "outputs": [],
      "source": [
        "!cd PETprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qju2_cJO10Wb"
      },
      "outputs": [],
      "source": [
        "!if [ -d \"PET_pipelines\" ]; then pushd PET_pipelines && git pull; else git clone https://github.com/openneuropet/PET_pipelines.git; fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "578shAXE2TMV"
      },
      "outputs": [],
      "source": [
        "!ls PET_pipelines/pyPetSurfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhkxGtPM2K-N"
      },
      "outputs": [],
      "source": [
        "%cd PET_pipelines/pyPetSurfer\n",
        "!wget /dev/null https://www.dropbox.com/sh/69dwtnv29wd7jlx/AADnw5FvAANpvzKAxVQTnyhBa?dl=0\n",
        "!if [ -f AADnw5FvAANpvzKAxVQTnyhBa?dl=0 ]; then unzip -o AADnw5FvAANpvzKAxVQTnyhBa?dl=0; fi\n",
        "!if [ ! -f AADnw5FvAANpvzKAxVQTnyhBa?dl=0 ]; then chmod +x ds001421-1.4.1.sh && mkdir ds001421-download/; fi\n",
        "!if [ ! -f AADnw5FvAANpvzKAxVQTnyhBa?dl=0 ]; then cp ds001421-1.4.1.sh ds001421-download/; fi\n",
        "!if [ ! -f AADnw5FvAANpvzKAxVQTnyhBa?dl=0 ]; then cd ds001421-download/ && ./ds001421-1.4.1.sh && rm ds001421-1.4.1.sh; fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4zrtiBq38UY"
      },
      "outputs": [],
      "source": [
        "os.environ['FREESURFER_HOME'] = freesurfer_home\n",
        "os.environ['SUBJECTS_DIR'] = subjects_dir\n",
        "!ls && python3 example.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK5I5qhJ31VJ"
      },
      "outputs": [],
      "source": [
        "!ls ."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}